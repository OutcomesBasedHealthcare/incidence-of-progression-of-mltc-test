{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### **01 - Incidence of MLTC**\r\n",
        "#### **01C02 - Manuscript outputs - main table progression rate - PRRs**\r\n",
        "\r\n",
        "This notebook takes the inputs from 01C01, and calculates Progression Rate Ratios (PRRs) and applies confidence intervals to both rates and PRRs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\r\n",
        "# required imports\r\n",
        "from scipy import stats\r\n",
        "import pyspark.sql.functions as F  # noqa: N812 F401\r\n",
        "\r\n",
        "# requires blank line after last import\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "if (!requireNamespace(\"PHEindicatormethods\", quietly = TRUE)) {\r\n",
        "  install.packages(\"PHEindicatormethods\")\r\n",
        "}\r\n",
        "library(PHEindicatormethods)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "%%pyspark\r\n",
        "# parameter cell\r\n",
        "incidence_schema = \"\"  # \"mltc_incidence_outputs_v40_20230331\"\r\n",
        "analysis_year = \"\"  # \"2022/23\"\r\n",
        "segmentation_schema = \"\"  # \"obh_segmentation_v40_20230331\"\r\n",
        "\r\n",
        "# optional, can be blank\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\r\n",
        "# Set parameters in Spark configuration with 'param.' prefix (for use in SQL cells)\r\n",
        "spark.conf.set(\"param.incidence_schema\", incidence_schema)\r\n",
        "spark.conf.set(\"param.analysis_year\", analysis_year)\r\n",
        "spark.conf.set(\"param.segmentation_schema\", segmentation_schema)\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "---\r\n",
        "\r\n",
        "#### **01C02 - Manuscript outputs - main table progression rates - PRRs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "\r\n",
        "**2022/23 main descriptive table - incidence of 1+, 2+, 3+ conditions overall and by socio-demographic breakdowns**\r\n",
        "\r\n",
        "Separate functions are used below to calculate\r\n",
        "- Rates and associated confidence intervals\r\n",
        "- PRRs and associated confidence intervals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Unpivot crude rates and calculate confidence intervals using Byar's method**\r\n",
        "\r\n",
        "Unpivoting is required to create a dataframe in the format needed to use `PHEindicatormethods` package `phe_rate` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    OR REPLACE TEMPORARY VIEW unpivoted AS\r\n",
        "SELECT    gender_description,\r\n",
        "          breakdown_type,\r\n",
        "          socio_demographic_breakdown,\r\n",
        "          '0 to 1+' AS transition,\r\n",
        "          person_years_0 AS person_years,\r\n",
        "          incidence_0_1_plus AS incidence\r\n",
        "FROM      ${param.incidence_schema}.mm_incidence_transitions_main_results\r\n",
        "UNION ALL\r\n",
        "SELECT    gender_description,\r\n",
        "          breakdown_type,\r\n",
        "          socio_demographic_breakdown,\r\n",
        "          '1 to 2+' AS transition,\r\n",
        "          person_years_1 AS person_years,\r\n",
        "          incidence_1_2_plus AS incidence\r\n",
        "FROM      ${param.incidence_schema}.mm_incidence_transitions_main_results\r\n",
        "UNION ALL\r\n",
        "SELECT    gender_description,\r\n",
        "          breakdown_type,\r\n",
        "          socio_demographic_breakdown,\r\n",
        "          '2 to 3+' AS transition,\r\n",
        "          person_years_2 AS person_years,\r\n",
        "          incidence_2_3_plus AS incidence\r\n",
        "FROM      ${param.incidence_schema}.mm_incidence_transitions_main_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Convert to RSpark DataFrame then R DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "df_unpivoted_r <- sql(\"SELECT * FROM unpivoted\")\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "r_unpivoted <- collect(df_unpivoted_r)\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Calculate crude rates and confidence intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Calculate rates with confidence intervals\r\n",
        "r_crude_rate_output <- phe_rate(\r\n",
        "  data = r_unpivoted,\r\n",
        "  x = incidence,\r\n",
        "  n = person_years,\r\n",
        "  multiplier = 100,\r\n",
        "  confidence = 0.95\r\n",
        ")\r\n",
        "\r\n",
        "# Convert the R DataFrame to a SparkR DataFrame\r\n",
        "df_r_crude_rate_output <- createDataFrame(r_crude_rate_output)\r\n",
        "\r\n",
        "# Save as a temporary view\r\n",
        "createOrReplaceTempView(df_r_crude_rate_output, \"r_crude_rate_output_view\")\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Crude Progression Rate Ratio (PRR) Confidence Interval Calculation**\r\n",
        "\r\n",
        "The Progression Rate Ratio (PRR) is used to compare progression rates between two populations. It is expressed as the ratio of incidence or progression rates between two distinct groups. This section calculates PRRs and their corresponding confidence intervals.\r\n",
        "\r\n",
        "**Methodology**\r\n",
        "\r\n",
        "1. **Data Inputs**:\r\n",
        "    - `events_col_1` and `events_col_2`: Number of progression events for Population 1 and Population 2, respectively.\r\n",
        "    - `person_years_col_1` and `person_years_col_2`: Person-years of observation for Population 1 and Population 2, respectively.\r\n",
        "    - `z_value`: Z-value for the desired confidence level, pre-calculated for efficiency (e.g. 1.96 for 95% confidence).\r\n",
        "\r\n",
        "2. **Calculate Crude Rates (CR)**:\r\n",
        "    - Crude rates are calculated as the number of events divided by the person-years of observation for each population.\r\n",
        "\r\n",
        "3. **Calculate Progression Rate Ratio (PRR)**:\r\n",
        "    - PRR is computed as the ratio of the two crude rates.\r\n",
        "\r\n",
        "4. **Estimate Variance of log(PRR)**:\r\n",
        "    - Variance of the logarithm of PRR is estimated using:\r\n",
        "      - *var_log_prr = 1 / events_col_1 + 1 / events_col_2*\r\n",
        "    - This variance determines the confidence interval width.\r\n",
        "\r\n",
        "5. **Confidence Interval Calculation**:\r\n",
        "    - Calculate lower and upper bounds for the PRR confidence interval using:\r\n",
        "      - *ci_lower_prr = exp(log(prr) - z_value * sqrt(var_log_prr))*\r\n",
        "      - *ci_upper_prr = exp(log(prr) + z_value * sqrt(var_log_prr))*\r\n",
        "\r\n",
        "**Output**\r\n",
        "\r\n",
        "The output includes:\r\n",
        "\r\n",
        "- Crude rates for both populations.\r\n",
        "- Calculated Progression Rate Ratio.\r\n",
        "- Lower and upper bounds of the PRR confidence interval.\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Restructure input data in required format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    OR REPLACE TEMPORARY VIEW prr_calculation_input AS\r\n",
        "SELECT    u0.gender_description,\r\n",
        "          u0.breakdown_type,\r\n",
        "          u0.socio_demographic_breakdown,\r\n",
        "          '1 to 2+' AS transition,\r\n",
        "          u0.person_years AS person_years_col_1,\r\n",
        "          u0.incidence AS events_col_1,\r\n",
        "          u1.person_years AS person_years_col_2,\r\n",
        "          u1.incidence AS events_col_2\r\n",
        "FROM      unpivoted u0\r\n",
        "INNER     JOIN unpivoted u1 ON u1.gender_description = u0.gender_description\r\n",
        "AND       u1.breakdown_type = u0.breakdown_type\r\n",
        "AND       u1.socio_demographic_breakdown = u0.socio_demographic_breakdown\r\n",
        "AND       u1.transition = '1 to 2+'\r\n",
        "WHERE     u0.transition = '0 to 1+'\r\n",
        "UNION ALL\r\n",
        "SELECT    u0.gender_description,\r\n",
        "          u0.breakdown_type,\r\n",
        "          u0.socio_demographic_breakdown,\r\n",
        "          '2 to 3+' AS transition,\r\n",
        "          u0.person_years AS person_years_col_1,\r\n",
        "          u0.incidence AS events_col_1,\r\n",
        "          u2.person_years AS person_years_col_2,\r\n",
        "          u2.incidence AS events_col_2\r\n",
        "FROM      unpivoted u0\r\n",
        "INNER     JOIN unpivoted u2 ON u2.gender_description = u0.gender_description\r\n",
        "AND       u2.breakdown_type = u0.breakdown_type\r\n",
        "AND       u2.socio_demographic_breakdown = u0.socio_demographic_breakdown\r\n",
        "AND       u2.transition = '2 to 3+'\r\n",
        "WHERE     u0.transition = '0 to 1+'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Set confidence level and calculate Z value (and set as a variable to be available in subsequent SQL cells)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\r\n",
        "# Define the confidence level\r\n",
        "confidence_level = 0.95\r\n",
        "\r\n",
        "# Calculate the Z-value for the given confidence level\r\n",
        "z_value = stats.norm.ppf((1 + confidence_level) / 2)\r\n",
        "\r\n",
        "spark.conf.set(\"param.z_value\", str(z_value))\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Create a temporary view for the crude rates and variance calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    OR REPLACE TEMPORARY VIEW crude_rates AS\r\n",
        "SELECT    gender_description,\r\n",
        "          breakdown_type,\r\n",
        "          socio_demographic_breakdown,\r\n",
        "          transition,\r\n",
        "          events_col_1,\r\n",
        "          person_years_col_1,\r\n",
        "          events_col_2,\r\n",
        "          person_years_col_2,\r\n",
        "          (events_col_1 / person_years_col_1) AS cr_population_1,\r\n",
        "          (events_col_2 / person_years_col_2) AS cr_population_2,\r\n",
        "          (events_col_2 / person_years_col_2) / (events_col_1 / person_years_col_1) AS progression_rate_ratio,\r\n",
        "          (1 / events_col_1) + (1 / events_col_2) AS var_log_prr\r\n",
        "FROM      prr_calculation_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Create a temporary view to calculate confidence intervals\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    OR REPLACE TEMPORARY VIEW prr_confidence_intervals AS\r\n",
        "SELECT    *,\r\n",
        "          EXP(LOG(progression_rate_ratio) - ${param.z_value} * SQRT(var_log_prr)) AS lower_confidence_interval_prr,\r\n",
        "          EXP(LOG(progression_rate_ratio) + ${param.z_value} * SQRT(var_log_prr)) AS upper_confidence_interval_prr\r\n",
        "FROM      crude_rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Create final view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    OR REPLACE TEMPORARY VIEW prr_results_view AS\r\n",
        "SELECT    gender_description,\r\n",
        "          breakdown_type,\r\n",
        "          socio_demographic_breakdown,\r\n",
        "          transition,\r\n",
        "          cr_population_1,\r\n",
        "          cr_population_2,\r\n",
        "          progression_rate_ratio,\r\n",
        "          lower_confidence_interval_prr,\r\n",
        "          upper_confidence_interval_prr\r\n",
        "FROM      prr_confidence_intervals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Create single combined output table with small number suppression applied**\r\n",
        "\r\n",
        "<blockquote style=\"color: #D8000C; background-color: #FFD2D2; padding: 10px; border-left: 6px solid #D8000C;\">\r\n",
        "  <strong>⚠️ Warning:</strong> DROP TABLE is currently commented out, as this table does not need to be recreated each time the incidence analysis is run.\r\n",
        "</blockquote>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "--DROP TABLE IF EXISTS ${param.incidence_schema}.output_01C02_incidence_results_main_table_PRRs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    TABLE ${param.incidence_schema}.output_01C02_incidence_results_main_table_PRRs USING PARQUET AS\r\n",
        "SELECT    m.gender_description,\r\n",
        "          m.breakdown_type,\r\n",
        "          m.socio_demographic_breakdown,\r\n",
        "          CASE\r\n",
        "                    WHEN m.unique_people_fy_period BETWEEN 1 AND 7  THEN '***'\r\n",
        "                    ELSE CAST(m.unique_people_fy_period AS STRING)\r\n",
        "          END AS unique_people_fy_period,\r\n",
        "          CASE\r\n",
        "                    WHEN m.unique_people_fy_end BETWEEN 1 AND 7  THEN '***'\r\n",
        "                    ELSE CAST(m.unique_people_fy_end AS STRING)\r\n",
        "          END AS unique_people_fy_end,\r\n",
        "          CASE\r\n",
        "                    WHEN m.person_years_0 BETWEEN 1 AND 7  THEN '***'\r\n",
        "                    ELSE CAST(m.person_years_0 AS STRING)\r\n",
        "          END AS person_years_0,\r\n",
        "          CASE\r\n",
        "                    WHEN m.incidence_0_1_plus BETWEEN 1 AND 7  THEN '***'\r\n",
        "                    ELSE CAST(m.incidence_0_1_plus AS STRING)\r\n",
        "          END AS incidence_0_1_plus,\r\n",
        "          m.progression_rate_0_1_plus,\r\n",
        "          r0.lowercl AS lower_cl_0_1,\r\n",
        "          r0.uppercl AS upper_cl_0_1,\r\n",
        "          CASE\r\n",
        "                    WHEN m.person_years_1 BETWEEN 1 AND 7  THEN '***'\r\n",
        "                    ELSE CAST(m.person_years_1 AS STRING)\r\n",
        "          END AS person_years_1,\r\n",
        "          CASE\r\n",
        "                    WHEN m.incidence_1_2_plus BETWEEN 1 AND 7  THEN '***'\r\n",
        "                    ELSE CAST(m.incidence_1_2_plus AS STRING)\r\n",
        "          END AS incidence_1_2_plus,\r\n",
        "          m.progression_rate_1_2_plus,\r\n",
        "          r1.lowercl AS lower_cl_1_2,\r\n",
        "          r1.uppercl AS upper_cl_1_2,\r\n",
        "          prr1.progression_rate_ratio AS prr_1_2,\r\n",
        "          prr1.lower_confidence_interval_prr AS lower_cl_prr_1_2,\r\n",
        "          prr1.upper_confidence_interval_prr AS upper_cl_prr_1_2,\r\n",
        "          CASE\r\n",
        "                    WHEN m.person_years_2 BETWEEN 1 AND 7  THEN '***'\r\n",
        "                    ELSE CAST(m.person_years_2 AS STRING)\r\n",
        "          END AS person_years_2,\r\n",
        "          CASE\r\n",
        "                    WHEN m.incidence_2_3_plus BETWEEN 1 AND 7  THEN '***'\r\n",
        "                    ELSE CAST(m.incidence_2_3_plus AS STRING)\r\n",
        "          END AS incidence_2_3_plus,\r\n",
        "          m.progression_rate_2_3_plus,\r\n",
        "          r2.lowercl AS lower_cl_2_3,\r\n",
        "          r2.uppercl AS upper_cl_2_3,\r\n",
        "          prr2.progression_rate_ratio AS prr_2_3,\r\n",
        "          prr2.lower_confidence_interval_prr AS lower_cl_prr_2_3,\r\n",
        "          prr2.upper_confidence_interval_prr AS upper_cl_prr_2_3\r\n",
        "FROM      ${param.incidence_schema}.mm_incidence_transitions_main_results m\r\n",
        "INNER     JOIN r_crude_rate_output_view r0 ON r0.gender_description = m.gender_description\r\n",
        "AND       r0.breakdown_type = m.breakdown_type\r\n",
        "AND       r0.socio_demographic_breakdown = m.socio_demographic_breakdown\r\n",
        "AND       r0.transition = '0 to 1+'\r\n",
        "INNER     JOIN r_crude_rate_output_view r1 ON r1.gender_description = m.gender_description\r\n",
        "AND       r1.breakdown_type = m.breakdown_type\r\n",
        "AND       r1.socio_demographic_breakdown = m.socio_demographic_breakdown\r\n",
        "AND       r1.transition = '1 to 2+'\r\n",
        "INNER     JOIN r_crude_rate_output_view r2 ON r2.gender_description = m.gender_description\r\n",
        "AND       r2.breakdown_type = m.breakdown_type\r\n",
        "AND       r2.socio_demographic_breakdown = m.socio_demographic_breakdown\r\n",
        "AND       r2.transition = '2 to 3+'\r\n",
        "INNER     JOIN prr_results_view prr1 ON prr1.gender_description = m.gender_description\r\n",
        "AND       prr1.breakdown_type = m.breakdown_type\r\n",
        "AND       prr1.socio_demographic_breakdown = m.socio_demographic_breakdown\r\n",
        "AND       prr1.transition = '1 to 2+'\r\n",
        "INNER     JOIN prr_results_view prr2 ON prr2.gender_description = m.gender_description\r\n",
        "AND       prr2.breakdown_type = m.breakdown_type\r\n",
        "AND       prr2.socio_demographic_breakdown = m.socio_demographic_breakdown\r\n",
        "AND       prr2.transition = '2 to 3+'\r\n",
        "ORDER BY  CASE\r\n",
        "                    WHEN m.gender_description = 'NA' THEN 0\r\n",
        "                    ELSE m.gender_description\r\n",
        "          END,\r\n",
        "          CASE\r\n",
        "                    WHEN m.breakdown_type = 'NA' THEN 0\r\n",
        "                    ELSE m.breakdown_type\r\n",
        "          END,\r\n",
        "          CASE\r\n",
        "                    WHEN m.socio_demographic_breakdown = 'NA' THEN 0\r\n",
        "                    ELSE m.socio_demographic_breakdown\r\n",
        "          END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "SELECT    *\r\n",
        "FROM      ${param.incidence_schema}.output_01C02_incidence_results_main_table_PRRs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Also extract unique count of people across the whole 6 year study period, to reference in Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "SELECT    *\r\n",
        "FROM      ${param.incidence_schema}.mm_incidence_period_population_6_years"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Finally, extract mean and SD age for 2022/23 to reference in the Results\r\n",
        "\r\n",
        "**1. Mean and median 2022/23 period population age** (person time approach)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "SELECT    COUNT(DISTINCT pseudo_nhs_number) AS people,\r\n",
        "          SUM(month_financial_year_fraction) AS person_time,\r\n",
        "          MIN(perc_50) AS median_age,\r\n",
        "          AVG(age_id) AS mean_age,\r\n",
        "          STD(age_id) AS standard_deviation_age\r\n",
        "FROM      (\r\n",
        "          SELECT    pseudo_nhs_number,\r\n",
        "                    f.date_id,\r\n",
        "                    month_financial_year_fraction,\r\n",
        "                    age_id,\r\n",
        "                    PERCENTILE_CONT (0.5) within GROUP (\r\n",
        "                    ORDER BY  age_id * 1.0\r\n",
        "                    ) OVER (\r\n",
        "                    PARTITION BY 1\r\n",
        "                    ) AS perc_50\r\n",
        "          FROM      ${param.segmentation_schema}.fact_model f\r\n",
        "          INNER     JOIN ${param.segmentation_schema}.dim_date d ON d.date_id = f.date_id\r\n",
        "          INNER     JOIN ${param.segmentation_schema}.dim_person p ON p.person_id = f.person_id\r\n",
        "          WHERE     f.gp_id IS NOT NULL\r\n",
        "          AND       f.age_id >= 20\r\n",
        "          AND       d.financial_year = '${param.analysis_year}'\r\n",
        "          ) x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**2. Mean and median 2022/23 period population age at entry to study (in selected year)** - i.e. min age for each person in 2022/23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "SELECT    COUNT(DISTINCT pseudo_nhs_number) AS people,\r\n",
        "          'N/A' AS person_time,\r\n",
        "          MIN(perc_50) AS median_age,\r\n",
        "          AVG(age_id) AS mean_age,\r\n",
        "          STD(age_id) AS standard_deviation_age\r\n",
        "FROM      (\r\n",
        "          SELECT    pseudo_nhs_number,\r\n",
        "                    age_id,\r\n",
        "                    PERCENTILE_CONT (0.5) within GROUP (\r\n",
        "                    ORDER BY  age_id * 1.0\r\n",
        "                    ) OVER (\r\n",
        "                    PARTITION BY 1\r\n",
        "                    ) AS perc_50\r\n",
        "          FROM      (\r\n",
        "                    SELECT    pseudo_nhs_number,\r\n",
        "                              MIN(age_id) AS age_id\r\n",
        "                    FROM      ${param.segmentation_schema}.fact_model f\r\n",
        "                    INNER     JOIN ${param.segmentation_schema}.dim_date d ON d.date_id = f.date_id\r\n",
        "                    INNER     JOIN ${param.segmentation_schema}.dim_person p ON p.person_id = f.person_id\r\n",
        "                    WHERE     f.gp_id IS NOT NULL\r\n",
        "                    AND       f.age_id >= 20\r\n",
        "                    AND       d.financial_year = '${param.analysis_year}'\r\n",
        "                    GROUP BY  pseudo_nhs_number\r\n",
        "                    ) x\r\n",
        "          ) y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**3. Mean and median 2022/23 snapshot population at start of year** - i.e. as of 30/04/2022 (the Segmentation Dataset is a monthly dataset, so this is the first monthly entry for 2022/23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "SELECT    COUNT(DISTINCT pseudo_nhs_number) AS people,\r\n",
        "          'N/A' AS person_time,\r\n",
        "          MIN(perc_50) AS median_age,\r\n",
        "          AVG(age_id) AS mean_age,\r\n",
        "          STD(age_id) AS standard_deviation_age\r\n",
        "FROM      (\r\n",
        "          SELECT    pseudo_nhs_number,\r\n",
        "                    f.date_id,\r\n",
        "                    age_id,\r\n",
        "                    PERCENTILE_CONT (0.5) within GROUP (\r\n",
        "                    ORDER BY  age_id * 1.0\r\n",
        "                    ) OVER (\r\n",
        "                    PARTITION BY 1\r\n",
        "                    ) AS perc_50\r\n",
        "          FROM      ${param.segmentation_schema}.fact_model f\r\n",
        "          INNER     JOIN (\r\n",
        "                    -- Earliest end of month snapshot within selected financial year\r\n",
        "                    SELECT    MIN(date_id) AS date_id\r\n",
        "                    FROM      ${param.segmentation_schema}.dim_date\r\n",
        "                    WHERE     financial_year = '${param.analysis_year}'\r\n",
        "                    AND       end_of_month IS TRUE\r\n",
        "                    ) d ON d.date_id = f.date_id\r\n",
        "          INNER     JOIN ${param.segmentation_schema}.dim_person p ON p.person_id = f.person_id\r\n",
        "          WHERE     f.gp_id IS NOT NULL\r\n",
        "          AND       f.age_id >= 20\r\n",
        "          ) x"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "r"
    }
  }
}