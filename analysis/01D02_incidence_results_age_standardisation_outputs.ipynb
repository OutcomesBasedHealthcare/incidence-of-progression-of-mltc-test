{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### **01 - Incidence of MLTC**\r\n",
        "#### **01D02 - Manuscript outputs - age standardisation outputs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "%%pyspark\r\n",
        "# required imports\r\n",
        "from scipy.stats import norm\r\n",
        "\r\n",
        "# requires blank line after last import\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "if (!requireNamespace(\"PHEindicatormethods\", quietly = TRUE)) {\r\n",
        "  install.packages(\"PHEindicatormethods\")\r\n",
        "}\r\n",
        "library(PHEindicatormethods)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Parameter cell**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "tags": []
      },
      "source": [
        "%%pyspark\r\n",
        "# parameter cell\r\n",
        "incidence_schema = \"\"  # \"mltc_incidence_outputs_v40_20230331\"\r\n",
        "\r\n",
        "# optional, can be blank\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\r\n",
        "# Set parameters in Spark configuration with 'param.' prefix (for use in SQL cells)\r\n",
        "spark.conf.set(\"param.incidence_schema\", incidence_schema)\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "---\r\n",
        "\r\n",
        "#### **01D02 - Manuscript outputs - age standardisation outputs**\r\n",
        "\r\n",
        "This section uses the phe_dsr R function from the PHEindicatormethods package to apply direct age standardisation, using the input table from the previous step.\r\n",
        "\r\n",
        "**Type of standardisation**: direct standardisation using the national population with 0 conditions as the standard population."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**a - Load data to a Spark DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "data <- sql(\"SELECT * FROM ${param.incidence_schema}.mm_incidence_age_standardisation_input\")\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**b - Convert to an R DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "r_data <- collect(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**c - Create separate R DataFrames for each unique combination of breakdowns**\r\n",
        "\r\n",
        "Create separate R DataFrames for each unique combination of \r\n",
        "- `gender_description`\r\n",
        "- `breakdown_type`\r\n",
        "- `socio_demographic_breakdown`\r\n",
        "- `initial_condition_count`\r\n",
        "\r\n",
        "This is required as the **phe_dsr** function does not accept breakdown columns, instead just calculating the standardised rate across all rows of data.\r\n",
        "\r\n",
        "Each DataFrame will contain the 10 year age band breakdown for the selected combination of breakdowns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Step 1: Get unique values for each of the columns\r\n",
        "unique_gender <- unique(r_data$gender_description)\r\n",
        "unique_breakdown_type <- unique(r_data$breakdown_type)\r\n",
        "unique_socio_demographic_breakdown <- unique(r_data$socio_demographic_breakdown)\r\n",
        "unique_initial_condition_count <- unique(r_data$initial_condition_count)\r\n",
        "\r\n",
        "# Step 2: Create all possible combinations of these unique values\r\n",
        "combinations <- expand.grid(gender_description = unique_gender,\r\n",
        "                            breakdown_type = unique_breakdown_type,\r\n",
        "                            socio_demographic_breakdown = unique_socio_demographic_breakdown,\r\n",
        "                            initial_condition_count = unique_initial_condition_count)\r\n",
        "\r\n",
        "# Step 3: Loop through each combination and create a subset dataframe\r\n",
        "dataframes_list <- list() # Initialize an empty list to store dataframes\r\n",
        "\r\n",
        "for(i in 1:nrow(combinations)) {\r\n",
        "  # Subset the original dataframe based on the current combination\r\n",
        "  subset_r_data <- r_data[r_data$gender_description == combinations$gender_description[i] &\r\n",
        "                  r_data$breakdown_type == combinations$breakdown_type[i] &\r\n",
        "                  r_data$socio_demographic_breakdown == combinations$socio_demographic_breakdown[i] &\r\n",
        "                  r_data$initial_condition_count == combinations$initial_condition_count[i], ]\r\n",
        "  \r\n",
        "  # Check if the subset dataframe is not empty\r\n",
        "  if(nrow(subset_r_data) > 0) {\r\n",
        "    # Store the subset dataframe in the list\r\n",
        "    r_data_name <- paste(\"r_data\", i, sep = \"_\")\r\n",
        "    dataframes_list[[r_data_name]] <- subset_r_data\r\n",
        "  }\r\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**d - Apply phe_dsr to each unique combination of breakdowns**\r\n",
        "\r\n",
        "Apply phe_dsr iteratively to each DataFrame created in the step above, with a unique combination of:\r\n",
        "- `gender_description`\r\n",
        "- `breakdown_type`\r\n",
        "- `socio_demographic_breakdown`\r\n",
        "- `initial_condition_count`\r\n",
        "\r\n",
        "Insert results into a combined DataFrame for each breakdown.\r\n",
        "\r\n",
        "<blockquote style=\"color: #333333; background-color: #FFBF00; padding: 10px; border-left: 6px solid #C48800;\">\r\n",
        "  <strong>⚠️ Warning:</strong> <code>phe_dsr</code> has been soft deprecated in \r\n",
        "  <a href=\"https://cran.r-project.org/web/packages/PHEindicatormethods/news/news.html\">PHEindicatormethods</a>, \r\n",
        "  replaced by <code>calculate_dsr</code>, which has more functionality. This will be removed from the package from September 2025 so should be replaced in any future code.  \r\n",
        "</blockquote>\r\n",
        "\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Initialize an empty dataframe to store the results\r\n",
        "results_df <- data.frame()\r\n",
        "\r\n",
        "# Iterate through each subset dataframe in dataframes_list\r\n",
        "for(i in seq_along(dataframes_list)) {\r\n",
        "  # Extract the current dataframe\r\n",
        "  current_df <- dataframes_list[[i]]\r\n",
        "  \r\n",
        "  # Run phe_dsr on the current dataframe\r\n",
        "  dsr_result <- phe_dsr(data = current_df,\r\n",
        "                        x = progression_incidence,\r\n",
        "                        n = person_years,\r\n",
        "                        stdpop = standard_pop_person_years,\r\n",
        "                        stdpoptype = \"field\",\r\n",
        "                        confidence = 0.95,\r\n",
        "                        multiplier = 100\r\n",
        "                        )\r\n",
        "  \r\n",
        "  # Add the breakdown columns based on values in first row\r\n",
        "  if(nrow(current_df) > 0) {\r\n",
        "    num_rows <- nrow(dsr_result)\r\n",
        "    dsr_result$gender_description <- rep(current_df$gender_description[1], num_rows)\r\n",
        "    dsr_result$breakdown_type <- rep(current_df$breakdown_type[1], num_rows)\r\n",
        "    dsr_result$socio_demographic_breakdown <- rep(current_df$socio_demographic_breakdown[1], num_rows)\r\n",
        "    dsr_result$initial_condition_count <- rep(current_df$initial_condition_count[1], num_rows)\r\n",
        "  }\r\n",
        "  \r\n",
        "  # Bind dsr_result to the results_df\r\n",
        "  results_df <- rbind(results_df, dsr_result)\r\n",
        "}\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**e - Convert back to a Spark DataFrame, then a SQL temporary view**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spark_df <- createDataFrame(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "createOrReplaceTempView(spark_df, \"age_standardised_rates\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**f - Calculating age standardised PRRs with confidence intervals**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Progression Rate Ratio (PRR) and Confidence Intervals Calculation:\r\n",
        "\r\n",
        "This SQL section computes the Progression Rate Ratio (PRR) between two populations and their confidence intervals. The PRR is derived from the Directly Standardised Rates (DSR) of each population. \r\n",
        "\r\n",
        "Key Steps:\r\n",
        "- **Standardisation**: Adjust population weights to sum to one.\r\n",
        "- **DSR Calculation**: Calculate the age-standardised incidence rate for each population.\r\n",
        "- **Variance Calculation**: Determine the variance of each DSR.\r\n",
        "- **PRR and Confidence Intervals**: Compute the PRR and its confidence intervals using the delta method and a specified confidence level.\r\n",
        "\r\n",
        "This process allows for a comparison of incidence rates between two populations while accounting for differences in age distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Restructure data into required format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    OR REPLACE TEMPORARY VIEW prr_calculation_input AS\r\n",
        "SELECT    u0.gender_description,\r\n",
        "          u0.breakdown_type,\r\n",
        "          u0.socio_demographic_breakdown,\r\n",
        "          u1.initial_condition_count,\r\n",
        "          u0.age_band as age,\r\n",
        "          u0.person_years AS person_years_population_1,\r\n",
        "          u0.progression_incidence AS number_of_events_population_1,\r\n",
        "          u1.person_years AS person_years_population_2,\r\n",
        "          u1.progression_incidence AS number_of_events_population_2,\r\n",
        "          u0.standard_pop_person_years as standard_population_weight\r\n",
        "FROM      ${param.incidence_schema}.mm_incidence_age_standardisation_input u0\r\n",
        "INNER     JOIN ${param.incidence_schema}.mm_incidence_age_standardisation_input u1 ON u1.gender_description = u0.gender_description\r\n",
        "AND       u1.breakdown_type = u0.breakdown_type\r\n",
        "AND       u1.socio_demographic_breakdown = u0.socio_demographic_breakdown\r\n",
        "AND       u1.age_band = u0.age_band\r\n",
        "AND       u1.initial_condition_count = 1\r\n",
        "WHERE     u0.initial_condition_count = 0\r\n",
        "UNION ALL\r\n",
        "SELECT    u0.gender_description,\r\n",
        "          u0.breakdown_type,\r\n",
        "          u0.socio_demographic_breakdown,\r\n",
        "          u2.initial_condition_count,\r\n",
        "          u0.age_band as age,\r\n",
        "          u0.person_years AS person_years_population_1,\r\n",
        "          u0.progression_incidence AS number_of_events_population_1,\r\n",
        "          u2.person_years AS person_years_population_2,\r\n",
        "          u2.progression_incidence AS number_of_events_population_2,\r\n",
        "          u0.standard_pop_person_years as standard_population_weight\r\n",
        "FROM      ${param.incidence_schema}.mm_incidence_age_standardisation_input u0\r\n",
        "INNER     JOIN ${param.incidence_schema}.mm_incidence_age_standardisation_input u2 ON u2.gender_description = u0.gender_description\r\n",
        "AND       u2.breakdown_type = u0.breakdown_type\r\n",
        "AND       u2.socio_demographic_breakdown = u0.socio_demographic_breakdown\r\n",
        "AND       u2.age_band = u0.age_band\r\n",
        "AND       u2.initial_condition_count = 2\r\n",
        "WHERE     u0.initial_condition_count = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Set confidence level and calculate Z value (and set as a variable to be available in subsequent SQL cells)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\r\n",
        "# Define the confidence level\r\n",
        "confidence_level = 0.95\r\n",
        "\r\n",
        "# Calculate the Z-value for the given confidence level\r\n",
        "z_value = norm.ppf((1 + confidence_level) / 2)\r\n",
        "\r\n",
        "spark.conf.set(\"param.z_value\", str(z_value))\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    OR REPLACE TEMPORARY VIEW standardised_weights AS\r\n",
        "SELECT    gender_description,\r\n",
        "          breakdown_type,\r\n",
        "          socio_demographic_breakdown,\r\n",
        "          initial_condition_count,\r\n",
        "          age,\r\n",
        "          person_years_population_1,\r\n",
        "          number_of_events_population_1,\r\n",
        "          person_years_population_2,\r\n",
        "          number_of_events_population_2,\r\n",
        "          standard_population_weight / SUM(standard_population_weight) OVER (\r\n",
        "          PARTITION BY gender_description,\r\n",
        "                    breakdown_type,\r\n",
        "                    socio_demographic_breakdown,\r\n",
        "                    initial_condition_count\r\n",
        "          ) AS standardized_weight\r\n",
        "FROM      prr_calculation_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    OR REPLACE TEMPORARY VIEW dsr_calculation AS\r\n",
        "SELECT    gender_description,\r\n",
        "          breakdown_type,\r\n",
        "          socio_demographic_breakdown,\r\n",
        "          initial_condition_count,\r\n",
        "          SUM(\r\n",
        "          standardized_weight * (number_of_events_population_1 / person_years_population_1)\r\n",
        "          ) AS dsr_population_1,\r\n",
        "          SUM(\r\n",
        "          standardized_weight * (number_of_events_population_2 / person_years_population_2)\r\n",
        "          ) AS dsr_population_2,\r\n",
        "          SUM(\r\n",
        "          (standardized_weight / person_years_population_1) * (standardized_weight / person_years_population_1) * number_of_events_population_1\r\n",
        "          ) AS var_pop1,\r\n",
        "          SUM(\r\n",
        "          (standardized_weight / person_years_population_2) * (standardized_weight / person_years_population_2) * number_of_events_population_2\r\n",
        "          ) AS var_pop2\r\n",
        "FROM      standardised_weights\r\n",
        "GROUP BY  gender_description,\r\n",
        "          breakdown_type,\r\n",
        "          socio_demographic_breakdown,\r\n",
        "          initial_condition_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    OR REPLACE TEMPORARY VIEW prr_calculation AS\r\n",
        "SELECT    gender_description,\r\n",
        "          breakdown_type,\r\n",
        "          socio_demographic_breakdown,\r\n",
        "          initial_condition_count,\r\n",
        "          dsr_population_1,\r\n",
        "          dsr_population_2,\r\n",
        "          dsr_population_2 / dsr_population_1 AS prr,\r\n",
        "          var_pop2 / (dsr_population_2 * dsr_population_2) + var_pop1 / (dsr_population_1 * dsr_population_1) AS var_log_prr\r\n",
        "FROM      dsr_calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    OR REPLACE TEMPORARY VIEW confidence_intervals AS\r\n",
        "SELECT    *,\r\n",
        "          EXP(LOG(prr) - ${param.z_value} * SQRT(var_log_prr)) AS ci_lower_prr,\r\n",
        "          EXP(LOG(prr) + ${param.z_value} * SQRT(var_log_prr)) AS ci_upper_prr\r\n",
        "FROM      prr_calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    OR REPLACE TEMPORARY VIEW age_standardised_prr AS\r\n",
        "SELECT    gender_description,\r\n",
        "          breakdown_type,\r\n",
        "          socio_demographic_breakdown,\r\n",
        "          initial_condition_count,\r\n",
        "          dsr_population_1,\r\n",
        "          dsr_population_2,\r\n",
        "          prr,\r\n",
        "          ci_lower_prr,\r\n",
        "          ci_upper_prr\r\n",
        "FROM      confidence_intervals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Extract results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "This first query extracts the main results\r\n",
        "- The combined IMD and ethnicity output is excluded, as it is dealt with separately below\r\n",
        "- Small number suppression is applied to the standard population and expected incidence figures (although is unlikely to be required, given these volumes are based on the standard population of people with 0 conditions)\r\n",
        "\r\n",
        "<blockquote style=\"color: #D8000C; background-color: #FFD2D2; padding: 10px; border-left: 6px solid #D8000C;\">\r\n",
        "  <strong>⚠️ Warning:</strong> DROP TABLE is currently commented out, as this table does not need to be recreated each time the incidence analysis is run.\r\n",
        "</blockquote>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        }
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "--DROP TABLE IF EXISTS ${param.incidence_schema}.output_01D02_incidence_results_age_standardisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    TABLE ${param.incidence_schema}.output_01D02_incidence_results_age_standardisation USING PARQUET AS\r\n",
        "SELECT    a0.gender_description,\r\n",
        "          a0.breakdown_type,\r\n",
        "          a0.socio_demographic_breakdown,\r\n",
        "          CASE WHEN a0.total_pop BETWEEN 1 AND 7 THEN '***' ELSE CAST(a0.total_pop AS STRING) END AS sp_person_years_0,\r\n",
        "          CASE WHEN a0.total_count BETWEEN 1 AND 7 THEN '***' ELSE CAST(a0.total_count AS STRING) END AS exp_incidence_0_1_plus,\r\n",
        "          a0.value AS progression_rate_0_1_plus,\r\n",
        "          a0.lowercl AS lower_cl_0_1,\r\n",
        "          a0.uppercl AS upper_cl_0_1,\r\n",
        "          CASE WHEN a1.total_pop BETWEEN 1 AND 7 THEN '***' ELSE CAST(a1.total_pop AS STRING) END AS sp_person_years_1,\r\n",
        "          CASE WHEN a1.total_count BETWEEN 1 AND 7 THEN '***' ELSE CAST(a1.total_count AS STRING) END AS exp_incidence_1_2_plus,\r\n",
        "          a1.value AS progression_rate_1_2_plus,\r\n",
        "          a1.lowercl AS lower_cl_1_2,\r\n",
        "          a1.uppercl AS upper_cl_1_2,\r\n",
        "          prr1.prr AS prr_1_2,\r\n",
        "          prr1.ci_lower_prr AS lower_cl_prr_1_2,\r\n",
        "          prr1.ci_upper_prr AS upper_cl_prr_1_2,\r\n",
        "          CASE WHEN a2.total_pop BETWEEN 1 AND 7 THEN '***' ELSE CAST(a2.total_pop AS STRING) END AS sp_person_years_2,\r\n",
        "          CASE WHEN a2.total_count BETWEEN 1 AND 7 THEN '***' ELSE CAST(a2.total_count AS STRING) END AS exp_incidence_2_3_plus,\r\n",
        "          a2.value AS progression_rate_2_3_plus,\r\n",
        "          a2.lowercl AS lower_cl_2_3,\r\n",
        "          a2.uppercl AS upper_cl_2_3,\r\n",
        "          prr2.prr AS prr_2_3,\r\n",
        "          prr2.ci_lower_prr AS lower_cl_prr_2_3,\r\n",
        "          prr2.ci_upper_prr AS upper_cl_prr_2_3\r\n",
        "FROM      age_standardised_rates a0\r\n",
        "INNER     JOIN age_standardised_rates a1 ON a1.gender_description = a0.gender_description\r\n",
        "AND       a1.breakdown_type = a0.breakdown_type\r\n",
        "AND       a1.socio_demographic_breakdown = a0.socio_demographic_breakdown\r\n",
        "AND       a1.initial_condition_count = 1\r\n",
        "INNER     JOIN age_standardised_rates a2 ON a2.gender_description = a0.gender_description\r\n",
        "AND       a2.breakdown_type = a0.breakdown_type\r\n",
        "AND       a2.socio_demographic_breakdown = a0.socio_demographic_breakdown\r\n",
        "AND       a2.initial_condition_count = 2\r\n",
        "INNER     JOIN age_standardised_prr prr1 ON prr1.gender_description = a0.gender_description\r\n",
        "AND       prr1.breakdown_type = a0.breakdown_type\r\n",
        "AND       prr1.socio_demographic_breakdown = a0.socio_demographic_breakdown\r\n",
        "AND       prr1.initial_condition_count = 1\r\n",
        "INNER     JOIN age_standardised_prr prr2 ON prr2.gender_description = a0.gender_description\r\n",
        "AND       prr2.breakdown_type = a0.breakdown_type\r\n",
        "AND       prr2.socio_demographic_breakdown = a0.socio_demographic_breakdown\r\n",
        "AND       prr2.initial_condition_count = 2\r\n",
        "WHERE     a0.initial_condition_count = 0\r\n",
        "AND       a0.breakdown_type <> 'IMD and Ethnicity'\r\n",
        "AND       a0.breakdown_type <> 'Gender, IMD and Ethnicity'\r\n",
        "ORDER BY  CASE\r\n",
        "                    WHEN a0.gender_description = 'NA' THEN 0\r\n",
        "                    ELSE a0.gender_description\r\n",
        "          END,\r\n",
        "          CASE\r\n",
        "                    WHEN a0.breakdown_type = 'NA' THEN 0\r\n",
        "                    ELSE a0.breakdown_type\r\n",
        "          END,\r\n",
        "          CASE\r\n",
        "                    WHEN a0.socio_demographic_breakdown = 'NA' THEN 0\r\n",
        "                    ELSE a0.socio_demographic_breakdown\r\n",
        "          END,\r\n",
        "          a0.initial_condition_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "SELECT    *\r\n",
        "FROM      ${param.incidence_schema}.output_01D02_incidence_results_age_standardisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "This second query extracts results for the combined IMD and ethnicity output.\r\n",
        "- This breakdown is dealt with separately, as IMD and ethnicity values are combined within the same `socio_demographic_breakdown` column, separated by a \" / \" delimiter\r\n",
        "- `socio_demographic_breakdown` is therefore split into two separate columns for IMD and Ethnicity\r\n",
        "- Small number suppression is applied to the standard population and expected incidence figures (although is unlikely to be required, given these volumes are based on the standard population of people with 0 conditions)\r\n",
        "\r\n",
        "<blockquote style=\"color: #D8000C; background-color: #FFD2D2; padding: 10px; border-left: 6px solid #D8000C;\">\r\n",
        "  <strong>⚠️ Warning:</strong> DROP TABLE is currently commented out, as this table does not need to be recreated each time the incidence analysis is run.\r\n",
        "</blockquote>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        }
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "--DROP TABLE IF EXISTS ${param.incidence_schema}.output_01D02_incidence_results_age_standardisation_ethnicity_imd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE    TABLE ${param.incidence_schema}.output_01D02_incidence_results_age_standardisation_ethnicity_imd USING PARQUET AS\r\n",
        "SELECT    a0.gender_description,\r\n",
        "          a0.breakdown_type,\r\n",
        "          split(a0.socio_demographic_breakdown, ' / ')[0] AS IMD, \r\n",
        "          split(a0.socio_demographic_breakdown, ' / ')[1] AS ethnicity,\r\n",
        "          CASE WHEN a0.total_pop BETWEEN 1 AND 7 THEN '***' ELSE CAST(a0.total_pop AS STRING) END AS sp_person_years_0,\r\n",
        "          CASE WHEN a0.total_count BETWEEN 1 AND 7 THEN '***' ELSE CAST(a0.total_count AS STRING) END AS exp_incidence_0_1_plus,\r\n",
        "          a0.value AS progression_rate_0_1_plus,\r\n",
        "          a0.lowercl AS lower_cl_0_1,\r\n",
        "          a0.uppercl AS upper_cl_0_1,\r\n",
        "          CASE WHEN a1.total_pop BETWEEN 1 AND 7 THEN '***' ELSE CAST(a1.total_pop AS STRING) END AS sp_person_years_1,\r\n",
        "          CASE WHEN a1.total_count BETWEEN 1 AND 7 THEN '***' ELSE CAST(a1.total_count AS STRING) END AS exp_incidence_1_2_plus,\r\n",
        "          a1.value AS progression_rate_1_2_plus,\r\n",
        "          a1.lowercl AS lower_cl_1_2,\r\n",
        "          a1.uppercl AS upper_cl_1_2,\r\n",
        "          prr1.prr AS prr_1_2,\r\n",
        "          prr1.ci_lower_prr AS lower_cl_prr_1_2,\r\n",
        "          prr1.ci_upper_prr AS upper_cl_prr_1_2,\r\n",
        "          CASE WHEN a2.total_pop BETWEEN 1 AND 7 THEN '***' ELSE CAST(a2.total_pop AS STRING) END AS sp_person_years_2,\r\n",
        "          CASE WHEN a2.total_count BETWEEN 1 AND 7 THEN '***' ELSE CAST(a2.total_count AS STRING) END AS exp_incidence_2_3_plus,\r\n",
        "          a2.value AS progression_rate_2_3_plus,\r\n",
        "          a2.lowercl AS lower_cl_2_3,\r\n",
        "          a2.uppercl AS upper_cl_2_3,\r\n",
        "          prr2.prr AS prr_2_3,\r\n",
        "          prr2.ci_lower_prr AS lower_cl_prr_2_3,\r\n",
        "          prr2.ci_upper_prr AS upper_cl_prr_2_3\r\n",
        "FROM      age_standardised_rates a0\r\n",
        "INNER     JOIN age_standardised_rates a1 ON a1.gender_description = a0.gender_description\r\n",
        "AND       a1.breakdown_type = a0.breakdown_type\r\n",
        "AND       a1.socio_demographic_breakdown = a0.socio_demographic_breakdown\r\n",
        "AND       a1.initial_condition_count = 1\r\n",
        "INNER     JOIN age_standardised_rates a2 ON a2.gender_description = a0.gender_description\r\n",
        "AND       a2.breakdown_type = a0.breakdown_type\r\n",
        "AND       a2.socio_demographic_breakdown = a0.socio_demographic_breakdown\r\n",
        "AND       a2.initial_condition_count = 2\r\n",
        "INNER     JOIN age_standardised_prr prr1 ON prr1.gender_description = a0.gender_description\r\n",
        "AND       prr1.breakdown_type = a0.breakdown_type\r\n",
        "AND       prr1.socio_demographic_breakdown = a0.socio_demographic_breakdown\r\n",
        "AND       prr1.initial_condition_count = 1\r\n",
        "INNER     JOIN age_standardised_prr prr2 ON prr2.gender_description = a0.gender_description\r\n",
        "AND       prr2.breakdown_type = a0.breakdown_type\r\n",
        "AND       prr2.socio_demographic_breakdown = a0.socio_demographic_breakdown\r\n",
        "AND       prr2.initial_condition_count = 2\r\n",
        "WHERE     a0.initial_condition_count = 0\r\n",
        "AND       (\r\n",
        "            a0.breakdown_type = 'IMD and Ethnicity'\r\n",
        "OR          a0.breakdown_type = 'Gender, IMD and Ethnicity'\r\n",
        "          )\r\n",
        "ORDER BY  CASE\r\n",
        "                    WHEN a0.gender_description = 'NA' THEN 0\r\n",
        "                    ELSE a0.gender_description\r\n",
        "          END,\r\n",
        "          a0.breakdown_type,\r\n",
        "          split(a0.socio_demographic_breakdown, ' / ')[0], \r\n",
        "          split(a0.socio_demographic_breakdown, ' / ')[1],\r\n",
        "          a0.initial_condition_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "SELECT    *\r\n",
        "FROM      ${param.incidence_schema}.output_01D02_incidence_results_age_standardisation_ethnicity_imd"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_sparkr",
      "display_name": "r"
    },
    "language_info": {
      "name": "r"
    }
  }
}